{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eddFRBbp8c-k"
      },
      "outputs": [],
      "source": [
        "# Import the necessary libraries:\n",
        "import os  # For reading files and managing paths\n",
        "import numpy as np  # For performing mathematical operations\n",
        "from scipy.sparse import lil_matrix  # For handling sparse matrices\n",
        "from sklearn.decomposition import TruncatedSVD  # For Singular Value Decomposition (SVD)\n",
        "from sklearn.metrics.pairwise import cosine_similarity  # For calculating cosine similarity between vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "i5LQ1V_f8fCG",
        "outputId": "c4dad22e-c533-4c1e-ab12-6d17eb056a4e"
      },
      "outputs": [
        {
          "ename": "UnicodeDecodeError",
          "evalue": "'charmap' codec can't decode byte 0x9d in position 490: character maps to <undefined>",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[1;32md:\\1.Coding\\lolcontexto\\gloVe_test.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/1.Coding/lolcontexto/gloVe_test.ipynb#W1sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m file_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(corpus_folder, file_name)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/1.Coding/lolcontexto/gloVe_test.ipynb#W1sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(file_path, \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m corpusFile:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/1.Coding/lolcontexto/gloVe_test.ipynb#W1sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39mfor\u001b[39;00m linea \u001b[39min\u001b[39;00m corpusFile:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/1.Coding/lolcontexto/gloVe_test.ipynb#W1sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m         word_line \u001b[39m=\u001b[39m linea\u001b[39m.\u001b[39mstrip()\u001b[39m.\u001b[39msplit()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/1.Coding/lolcontexto/gloVe_test.ipynb#W1sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m         corpus\u001b[39m.\u001b[39mextend(word_line)\n",
            "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.1776.0_x64__qbz5n2kfra8p0\\Lib\\encodings\\cp1252.py:23\u001b[0m, in \u001b[0;36mIncrementalDecoder.decode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m---> 23\u001b[0m     \u001b[39mreturn\u001b[39;00m codecs\u001b[39m.\u001b[39mcharmap_decode(\u001b[39minput\u001b[39m,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39merrors,decoding_table)[\u001b[39m0\u001b[39m]\n",
            "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x9d in position 490: character maps to <undefined>"
          ]
        }
      ],
      "source": [
        "# Define the path to the corpus folder and obtain the list of text files\n",
        "corpus_folder = \"./corpus\"\n",
        "file_names = [f for f in os.listdir(corpus_folder) if f.endswith(\".txt\")]\n",
        "\n",
        "# Initialize an empty list to store the words from the corpus\n",
        "corpus = []\n",
        "\n",
        "# Read each text file in the corpus folder and append the words to the corpus list\n",
        "for file_name in file_names:\n",
        "    file_path = os.path.join(corpus_folder, file_name)\n",
        "    with open(file_path, \"r\") as corpusFile:\n",
        "        for linea in corpusFile:\n",
        "            word_line = linea.strip().split()\n",
        "            corpus.extend(word_line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BkFSNky-9c89"
      },
      "outputs": [],
      "source": [
        "# Function to create a co-occurrence matrix from the corpus with a given window size\n",
        "def create_co_occurrence_matrix(corpus, window_size=4):\n",
        "    vocab = set(corpus)  # Create a set of unique words in the corpus\n",
        "    word2id = {word: i for i, word in enumerate(vocab)}  # Create a word-to-index dictionary for the words\n",
        "    id2word = {i: word for i, word in enumerate(vocab)}  # Create an index-to-word dictionary for the words\n",
        "    matrix = lil_matrix((len(vocab), len(vocab)))  # Initialize an empty sparse matrix of size len(vocab) x len(vocab)\n",
        "\n",
        "    # Iterate through the corpus to fill the co-occurrence matrix\n",
        "    for i in range(len(corpus)):\n",
        "        for j in range(max(0, i - window_size), min(len(corpus), i + window_size)):\n",
        "            if i != j:\n",
        "                matrix[word2id[corpus[i]], word2id[corpus[j]]] += 1\n",
        "\n",
        "    return matrix, word2id, id2word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4a_wAjxa9gC0"
      },
      "outputs": [],
      "source": [
        "# Function to perform SVD on the co-occurrence matrix and reduce the dimensionality\n",
        "def perform_svd(matrix, n_components=300):\n",
        "    n_components = min(n_components, matrix.shape[1] - 1)\n",
        "    svd = TruncatedSVD(n_components=n_components)\n",
        "    return svd.fit_transform(matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCxo9rA09gay"
      },
      "outputs": [],
      "source": [
        "# Function to create word embeddings from the corpus using the co-occurrence matrix and SVD\n",
        "def create_word_embeddings(corpus):\n",
        "    matrix, word2id, id2word = create_co_occurrence_matrix(corpus)  # Create the co-occurrence matrix\n",
        "    word_embeddings = perform_svd(matrix)  # Perform SVD on the matrix\n",
        "    return word_embeddings, word2id, id2word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IhwnpAwG9hq5"
      },
      "outputs": [],
      "source": [
        "# Create the word embeddings from the given corpus\n",
        "embeddings, word2id, id2word = create_word_embeddings(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lywcyqZJ9jux"
      },
      "outputs": [],
      "source": [
        "# Function to calculate the cosine similarity between two word vectors\n",
        "def get_word_similarity(embeddings, word2id, word1, word2):\n",
        "    word1_vector = embeddings[word2id[word1]]  # Get the vector representation of word1\n",
        "    word2_vector = embeddings[word2id[word2]]  # Get the vector representation of word2\n",
        "\n",
        "    # Compute the cosine similarity between the two vectors\n",
        "    similarity = cosine_similarity(word1_vector.reshape(1, -1), word2_vector.reshape(1, -1))\n",
        "\n",
        "    return similarity[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C8AWmvwP9lAs"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The distance between the two words is: 0.1576220207772147\n"
          ]
        }
      ],
      "source": [
        "# Example usage: Calculate the similarity between the word embeddings for 'sun' and 'sky'\n",
        "similarity = get_word_similarity(embeddings, word2id, 'Darius', 'Katarina')\n",
        "print(f\"The distance between the two words is: {similarity}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "5h1VmddR2YOR",
        "outputId": "bc551814-5a94-47fb-8502-3f2ac2108289"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The distance between the two words is: 0.3043478081958932\n"
          ]
        }
      ],
      "source": [
        "similarity = get_word_similarity(embeddings, word2id, 'Ahri', 'Katarina')\n",
        "print(f\"The distance between the two words is: {similarity}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The distance between the two words is: 0.25354712418326303\n"
          ]
        }
      ],
      "source": [
        "similarity = get_word_similarity(embeddings, word2id, 'Darius', 'Aatrox')\n",
        "print(f\"The distance between the two words is: {similarity}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Similarity between Aatrox and Aatrox: 1.0\n",
            "Similarity between Aatrox and Ahri: 0.2797515901192059\n",
            "Similarity between Aatrox and Darius: 0.25354712418326303\n",
            "Similarity between Aatrox and Katarina: 0.2797515691418397\n",
            "Similarity between Ahri and Aatrox: 0.2797515901192059\n",
            "Similarity between Ahri and Ahri: 0.9999999999999998\n",
            "Similarity between Ahri and Darius: 0.15762198150904974\n",
            "Similarity between Ahri and Katarina: 0.3043478081958932\n",
            "Similarity between Darius and Aatrox: 0.25354712418326303\n",
            "Similarity between Darius and Ahri: 0.15762198150904974\n",
            "Similarity between Darius and Darius: 1.0\n",
            "Similarity between Darius and Katarina: 0.1576220207772147\n",
            "Similarity between Katarina and Aatrox: 0.2797515691418397\n",
            "Similarity between Katarina and Ahri: 0.3043478081958932\n",
            "Similarity between Katarina and Darius: 0.1576220207772147\n",
            "Similarity between Katarina and Katarina: 0.9999999999999991\n"
          ]
        }
      ],
      "source": [
        "champions = [\"Aatrox\", \"Ahri\", \"Darius\", \"Katarina\"]\n",
        "\n",
        "for c1 in champions:\n",
        "    for c2 in champions:\n",
        "        similarity = get_word_similarity(embeddings, word2id, c1, c2)\n",
        "        print(f\"Similarity between {c1} and {c2}: {similarity}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rank 1: Ahri\n",
            "Rank 2: Katarina\n",
            "Rank 3: Aatrox\n",
            "Rank 4: Darius\n"
          ]
        }
      ],
      "source": [
        "# Create a list of tuples with champion names and their similarity scores to 'Aatrox'\n",
        "similarity_scores = [(c, get_word_similarity(embeddings, word2id, \"Ahri\", c)) for c in champions]\n",
        "\n",
        "# Sort the list based on similarity scores in descending order\n",
        "similarity_scores.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Create a ranking dictionary\n",
        "ranking = {champion: rank + 1 for rank, (champion, _) in enumerate(similarity_scores)}\n",
        "\n",
        "# Print the rankings\n",
        "for champion, rank in ranking.items():\n",
        "    print(f\"Rank {rank}: {champion}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
