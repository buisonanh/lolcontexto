{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eddFRBbp8c-k"
      },
      "outputs": [],
      "source": [
        "# Import the necessary libraries:\n",
        "import os  # For reading files and managing paths\n",
        "import numpy as np  # For performing mathematical operations\n",
        "from scipy.sparse import lil_matrix  # For handling sparse matrices\n",
        "from sklearn.decomposition import TruncatedSVD  # For Singular Value Decomposition (SVD)\n",
        "from sklearn.metrics.pairwise import cosine_similarity  # For calculating cosine similarity between vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "i5LQ1V_f8fCG",
        "outputId": "c4dad22e-c533-4c1e-ab12-6d17eb056a4e"
      },
      "outputs": [],
      "source": [
        "# Define the path to the corpus folder and obtain the list of text files\n",
        "corpus_folder = \"./corpus\"\n",
        "file_names = [f for f in os.listdir(corpus_folder) if f.endswith(\".txt\")]\n",
        "\n",
        "# Initialize an empty list to store the words from the corpus\n",
        "corpus = []\n",
        "\n",
        "# Read each text file in the corpus folder and append the words to the corpus list\n",
        "for file_name in file_names:\n",
        "    file_path = os.path.join(corpus_folder, file_name)\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as corpusFile:\n",
        "        for linea in corpusFile:\n",
        "            word_line = linea.strip().split()\n",
        "            corpus.extend(word_line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BkFSNky-9c89"
      },
      "outputs": [],
      "source": [
        "# Function to create a co-occurrence matrix from the corpus with a given window size\n",
        "def create_co_occurrence_matrix(corpus, window_size=4):\n",
        "    vocab = set(corpus)  # Create a set of unique words in the corpus\n",
        "    word2id = {word: i for i, word in enumerate(vocab)}  # Create a word-to-index dictionary for the words\n",
        "    id2word = {i: word for i, word in enumerate(vocab)}  # Create an index-to-word dictionary for the words\n",
        "    matrix = lil_matrix((len(vocab), len(vocab)))  # Initialize an empty sparse matrix of size len(vocab) x len(vocab)\n",
        "\n",
        "    # Iterate through the corpus to fill the co-occurrence matrix\n",
        "    for i in range(len(corpus)):\n",
        "        for j in range(max(0, i - window_size), min(len(corpus), i + window_size)):\n",
        "            if i != j:\n",
        "                matrix[word2id[corpus[i]], word2id[corpus[j]]] += 1\n",
        "\n",
        "    return matrix, word2id, id2word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4a_wAjxa9gC0"
      },
      "outputs": [],
      "source": [
        "# Function to perform SVD on the co-occurrence matrix and reduce the dimensionality\n",
        "def perform_svd(matrix, n_components=300):\n",
        "    n_components = min(n_components, matrix.shape[1] - 1)\n",
        "    svd = TruncatedSVD(n_components=n_components)\n",
        "    return svd.fit_transform(matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zCxo9rA09gay"
      },
      "outputs": [],
      "source": [
        "# Function to create word embeddings from the corpus using the co-occurrence matrix and SVD\n",
        "def create_word_embeddings(corpus):\n",
        "    matrix, word2id, id2word = create_co_occurrence_matrix(corpus)  # Create the co-occurrence matrix\n",
        "    word_embeddings = perform_svd(matrix)  # Perform SVD on the matrix\n",
        "    return word_embeddings, word2id, id2word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "IhwnpAwG9hq5"
      },
      "outputs": [],
      "source": [
        "# Create the word embeddings from the given corpus\n",
        "embeddings, word2id, id2word = create_word_embeddings(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "lywcyqZJ9jux"
      },
      "outputs": [],
      "source": [
        "# Function to calculate the cosine similarity between two word vectors\n",
        "def get_word_similarity(embeddings, word2id, word1, word2):\n",
        "    word1_vector = embeddings[word2id[word1]]  # Get the vector representation of word1\n",
        "    word2_vector = embeddings[word2id[word2]]  # Get the vector representation of word2\n",
        "\n",
        "    # Compute the cosine similarity between the two vectors\n",
        "    similarity = cosine_similarity(word1_vector.reshape(1, -1), word2_vector.reshape(1, -1))\n",
        "\n",
        "    return similarity[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "C8AWmvwP9lAs"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The distance between the two words is: 0.743156407655106\n"
          ]
        }
      ],
      "source": [
        "# Example usage: Calculate the similarity between the word embeddings for 'sun' and 'sky'\n",
        "similarity = get_word_similarity(embeddings, word2id, 'darius', 'katarina')\n",
        "print(f\"The distance between the two words is: {similarity}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "5h1VmddR2YOR",
        "outputId": "bc551814-5a94-47fb-8502-3f2ac2108289"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The distance between the two words is: 0.9024500365341869\n"
          ]
        }
      ],
      "source": [
        "similarity = get_word_similarity(embeddings, word2id, 'yasuo', 'yone')\n",
        "print(f\"The distance between the two words is: {similarity}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The distance between the two words is: 0.9931367752085789\n"
          ]
        }
      ],
      "source": [
        "similarity = get_word_similarity(embeddings, word2id, 'darius', 'aatrox')\n",
        "print(f\"The distance between the two words is: {similarity}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['aatrox', 'ahri', 'akali', 'akshan', 'alistar', 'amumu', 'anivia', 'annie', 'aphelios', 'ashe', 'aurelion-sol', 'azir', 'bard', 'bel-veth', 'blitzcrank', 'brand', 'braum', 'briar', 'caitlyn', 'camille', 'cassiopeia', 'cho-gath', 'corki', 'darius', 'diana', 'dr-mundo', 'draven', 'ekko', 'elise', 'evelynn', 'ezreal', 'fiddlesticks', 'fiora', 'fizz', 'galio', 'gangplank', 'garen', 'gnar', 'gragas', 'graves', 'gwen', 'hecarim', 'heimerdinger', 'illaoi', 'irelia', 'ivern', 'janna', 'jarvan-iv', 'jax', 'jayce', 'jhin', 'jinx', 'k-sante', 'kai-sa', 'kalista', 'karma', 'karthus', 'kassadin', 'katarina', 'kayle', 'kayn', 'kennen', 'kha-zix', 'kindred', 'kled', 'kog-maw', 'leblanc', 'lee-sin', 'leona', 'lillia', 'lissandra', 'lucian', 'lulu', 'lux', 'malphite', 'malzahar', 'maokai', 'master-yi', 'milio', 'miss-fortune', 'mordekaiser', 'morgana', 'naafiri', 'nami', 'nasus', 'nautilus', 'neeko', 'nidalee', 'nilah', 'nocturne', 'nunu', 'olaf', 'orianna', 'ornn', 'pantheon', 'poppy', 'pyke', 'qiyana', 'quinn', 'rakan', 'rammus', 'rek-sai', 'rell', 'renata', 'renekton', 'rengar', 'riven', 'rumble', 'ryze', 'samira', 'sejuani', 'senna', 'seraphine', 'sett', 'shaco', 'shen', 'shyvana', 'singed', 'sion', 'sivir', 'skarner', 'sona', 'soraka', 'swain', 'sylas', 'syndra', 'tahm-kench', 'taliyah', 'talon', 'taric', 'teemo', 'thresh', 'tristana', 'trundle', 'tryndamere', 'twisted-fate', 'twitch', 'udyr', 'urgot', 'varus', 'vayne', 'veigar', 'vel-koz', 'vex', 'vi', 'viego', 'viktor', 'vladimir', 'volibear', 'warwick', 'wukong', 'xayah', 'xerath', 'xin-zhao', 'yasuo', 'yone', 'yorick', 'yuumi', 'zac', 'zed', 'zeri', 'ziggs', 'zilean', 'zoe', 'zyra']\n"
          ]
        }
      ],
      "source": [
        "# opening the file in read mode \n",
        "my_file = open(\"champ_list.txt\", \"r\") \n",
        "\n",
        "# reading the file \n",
        "data = my_file.read() \n",
        "\n",
        "# replacing end splitting the text  \n",
        "# when newline ('\\n') is seen. \n",
        "champions = data.split(\", \") \n",
        "print(champions) \n",
        "\n",
        "my_file.close() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rank 1: garen\n",
            "Rank 2: fiora\n",
            "Rank 3: rumble\n",
            "Rank 4: aatrox\n",
            "Rank 5: darius\n",
            "Rank 6: jayce\n",
            "Rank 7: gwen\n",
            "Rank 8: skarner\n",
            "Rank 9: olaf\n",
            "Rank 10: shyvana\n",
            "Rank 11: renekton\n",
            "Rank 12: kayle\n",
            "Rank 13: lee-sin\n",
            "Rank 14: warwick\n",
            "Rank 15: nilah\n",
            "Rank 16: udyr\n",
            "Rank 17: camille\n",
            "Rank 18: diana\n",
            "Rank 19: gnar\n",
            "Rank 20: gragas\n",
            "Rank 21: urgot\n",
            "Rank 22: gangplank\n",
            "Rank 23: bel-veth\n",
            "Rank 24: nasus\n",
            "Rank 25: sett\n",
            "Rank 26: pantheon\n",
            "Rank 27: trundle\n",
            "Rank 28: lillia\n",
            "Rank 29: rek-sai\n",
            "Rank 30: yorick\n",
            "Rank 31: tryndamere\n",
            "Rank 32: volibear\n",
            "Rank 33: yasuo\n",
            "Rank 34: hecarim\n",
            "Rank 35: wukong\n",
            "Rank 36: kayn\n",
            "Rank 37: vi\n",
            "Rank 38: illaoi\n",
            "Rank 39: kog-maw\n",
            "Rank 40: briar\n",
            "Rank 41: mordekaiser\n",
            "Rank 42: xin-zhao\n",
            "Rank 43: irelia\n",
            "Rank 44: riven\n",
            "Rank 45: kled\n",
            "Rank 46: dr-mundo\n",
            "Rank 47: jax\n",
            "Rank 48: zilean\n",
            "Rank 49: katarina\n",
            "Rank 50: leona\n",
            "Rank 51: lissandra\n",
            "Rank 52: aurelion-sol\n",
            "Rank 53: viktor\n",
            "Rank 54: talon\n",
            "Rank 55: miss-fortune\n",
            "Rank 56: yone\n",
            "Rank 57: fiddlesticks\n",
            "Rank 58: sylas\n",
            "Rank 59: ekko\n",
            "Rank 60: ahri\n",
            "Rank 61: pyke\n",
            "Rank 62: braum\n",
            "Rank 63: naafiri\n",
            "Rank 64: thresh\n",
            "Rank 65: nocturne\n",
            "Rank 66: leblanc\n",
            "Rank 67: qiyana\n",
            "Rank 68: vladimir\n",
            "Rank 69: jhin\n",
            "Rank 70: seraphine\n",
            "Rank 71: shen\n",
            "Rank 72: amumu\n",
            "Rank 73: sejuani\n",
            "Rank 74: cho-gath\n",
            "Rank 75: brand\n",
            "Rank 76: poppy\n",
            "Rank 77: viego\n",
            "Rank 78: jinx\n",
            "Rank 79: rengar\n",
            "Rank 80: ezreal\n",
            "Rank 81: evelynn\n",
            "Rank 82: vel-koz\n",
            "Rank 83: azir\n",
            "Rank 84: draven\n",
            "Rank 85: shaco\n",
            "Rank 86: xayah\n",
            "Rank 87: aphelios\n",
            "Rank 88: orianna\n",
            "Rank 89: fizz\n",
            "Rank 90: zyra\n",
            "Rank 91: varus\n",
            "Rank 92: lux\n",
            "Rank 93: veigar\n",
            "Rank 94: milio\n",
            "Rank 95: cassiopeia\n",
            "Rank 96: zed\n",
            "Rank 97: jarvan-iv\n",
            "Rank 98: karthus\n",
            "Rank 99: graves\n",
            "Rank 100: sivir\n",
            "Rank 101: swain\n",
            "Rank 102: neeko\n",
            "Rank 103: kalista\n",
            "Rank 104: elise\n",
            "Rank 105: anivia\n",
            "Rank 106: tahm-kench\n",
            "Rank 107: galio\n",
            "Rank 108: nidalee\n",
            "Rank 109: lulu\n",
            "Rank 110: master-yi\n",
            "Rank 111: xerath\n",
            "Rank 112: twitch\n",
            "Rank 113: twisted-fate\n",
            "Rank 114: singed\n",
            "Rank 115: ashe\n",
            "Rank 116: zac\n",
            "Rank 117: bard\n",
            "Rank 118: vex\n",
            "Rank 119: soraka\n",
            "Rank 120: sona\n",
            "Rank 121: nami\n",
            "Rank 122: renata\n",
            "Rank 123: kassadin\n",
            "Rank 124: taric\n",
            "Rank 125: akali\n",
            "Rank 126: rakan\n",
            "Rank 127: k-sante\n",
            "Rank 128: kha-zix\n",
            "Rank 129: ornn\n",
            "Rank 130: blitzcrank\n",
            "Rank 131: heimerdinger\n",
            "Rank 132: janna\n",
            "Rank 133: alistar\n",
            "Rank 134: ziggs\n",
            "Rank 135: nunu\n",
            "Rank 136: rell\n",
            "Rank 137: kai-sa\n",
            "Rank 138: zeri\n",
            "Rank 139: annie\n",
            "Rank 140: senna\n",
            "Rank 141: zoe\n",
            "Rank 142: caitlyn\n",
            "Rank 143: samira\n",
            "Rank 144: corki\n",
            "Rank 145: akshan\n",
            "Rank 146: ivern\n",
            "Rank 147: yuumi\n",
            "Rank 148: rammus\n",
            "Rank 149: quinn\n",
            "Rank 150: sion\n",
            "Rank 151: tristana\n",
            "Rank 152: maokai\n",
            "Rank 153: nautilus\n",
            "Rank 154: kindred\n",
            "Rank 155: taliyah\n",
            "Rank 156: syndra\n",
            "Rank 157: malzahar\n",
            "Rank 158: teemo\n",
            "Rank 159: karma\n",
            "Rank 160: malphite\n",
            "Rank 161: ryze\n",
            "Rank 162: vayne\n",
            "Rank 163: lucian\n",
            "Rank 164: morgana\n",
            "Rank 165: kennen\n"
          ]
        }
      ],
      "source": [
        "# Create a list of tuples with champion names and their similarity scores to 'Aatrox'\n",
        "similarity_scores = [(c, get_word_similarity(embeddings, word2id, \"garen\", c)) for c in champions]\n",
        "\n",
        "# Sort the list based on similarity scores in descending order\n",
        "similarity_scores.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Create a ranking dictionary\n",
        "ranking = {champion: rank + 1 for rank, (champion, _) in enumerate(similarity_scores)}\n",
        "\n",
        "# Print the rankings\n",
        "for champion, rank in ranking.items():\n",
        "    print(f\"Rank {rank}: {champion}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
